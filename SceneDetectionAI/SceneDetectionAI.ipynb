{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14034 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "training_set = train_datagen.flow_from_directory('seg_train/',target_size=(64,64),batch_size= 64,class_mode= 'categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_set = test_datagen.flow_from_directory('seg_test/',target_size=(64,64),batch_size= 64,class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=5,activation='relu',input_shape = [64,64,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2,strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=5, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=128,activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=6,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# > Training the CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "220/220 [==============================] - 135s 615ms/step - loss: 1.0974 - accuracy: 0.5715 - val_loss: 0.8848 - val_accuracy: 0.6650\n",
      "Epoch 2/25\n",
      "220/220 [==============================] - 47s 212ms/step - loss: 0.8692 - accuracy: 0.6692 - val_loss: 0.7935 - val_accuracy: 0.7123\n",
      "Epoch 3/25\n",
      "220/220 [==============================] - 47s 213ms/step - loss: 0.7836 - accuracy: 0.7084 - val_loss: 0.7558 - val_accuracy: 0.7347\n",
      "Epoch 4/25\n",
      "220/220 [==============================] - 47s 212ms/step - loss: 0.7115 - accuracy: 0.7350 - val_loss: 0.6929 - val_accuracy: 0.7607\n",
      "Epoch 5/25\n",
      "220/220 [==============================] - 47s 212ms/step - loss: 0.6641 - accuracy: 0.7550 - val_loss: 0.6877 - val_accuracy: 0.7677\n",
      "Epoch 6/25\n",
      "220/220 [==============================] - 47s 215ms/step - loss: 0.6360 - accuracy: 0.7641 - val_loss: 0.6302 - val_accuracy: 0.7840\n",
      "Epoch 7/25\n",
      "220/220 [==============================] - 47s 212ms/step - loss: 0.5963 - accuracy: 0.7830 - val_loss: 0.6350 - val_accuracy: 0.7797\n",
      "Epoch 8/25\n",
      "220/220 [==============================] - 47s 212ms/step - loss: 0.5619 - accuracy: 0.7956 - val_loss: 0.7068 - val_accuracy: 0.7503\n",
      "Epoch 9/25\n",
      "220/220 [==============================] - 46s 211ms/step - loss: 0.5533 - accuracy: 0.8013 - val_loss: 0.6875 - val_accuracy: 0.7580\n",
      "Epoch 10/25\n",
      "220/220 [==============================] - 47s 212ms/step - loss: 0.5209 - accuracy: 0.8153 - val_loss: 0.6004 - val_accuracy: 0.7993\n",
      "Epoch 11/25\n",
      "220/220 [==============================] - 47s 212ms/step - loss: 0.5017 - accuracy: 0.8209 - val_loss: 0.5992 - val_accuracy: 0.8003\n",
      "Epoch 12/25\n",
      "220/220 [==============================] - 47s 213ms/step - loss: 0.4790 - accuracy: 0.8270 - val_loss: 0.6317 - val_accuracy: 0.7910\n",
      "Epoch 13/25\n",
      "220/220 [==============================] - 47s 215ms/step - loss: 0.4595 - accuracy: 0.8335 - val_loss: 0.6462 - val_accuracy: 0.7857\n",
      "Epoch 14/25\n",
      "220/220 [==============================] - 48s 217ms/step - loss: 0.4477 - accuracy: 0.8368 - val_loss: 0.6389 - val_accuracy: 0.7817\n",
      "Epoch 15/25\n",
      "220/220 [==============================] - 48s 216ms/step - loss: 0.4214 - accuracy: 0.8482 - val_loss: 0.6240 - val_accuracy: 0.8033\n",
      "Epoch 16/25\n",
      "220/220 [==============================] - 47s 215ms/step - loss: 0.4166 - accuracy: 0.8488 - val_loss: 0.6211 - val_accuracy: 0.7957\n",
      "Epoch 17/25\n",
      "220/220 [==============================] - 47s 213ms/step - loss: 0.4078 - accuracy: 0.8537 - val_loss: 0.6361 - val_accuracy: 0.7883\n",
      "Epoch 18/25\n",
      "220/220 [==============================] - 48s 218ms/step - loss: 0.3741 - accuracy: 0.8661 - val_loss: 0.6227 - val_accuracy: 0.7983\n",
      "Epoch 19/25\n",
      "220/220 [==============================] - 46s 211ms/step - loss: 0.3710 - accuracy: 0.8670 - val_loss: 0.6111 - val_accuracy: 0.8070\n",
      "Epoch 20/25\n",
      "220/220 [==============================] - 50s 227ms/step - loss: 0.3617 - accuracy: 0.8690 - val_loss: 0.6372 - val_accuracy: 0.8123\n",
      "Epoch 21/25\n",
      "220/220 [==============================] - 48s 217ms/step - loss: 0.3331 - accuracy: 0.8777 - val_loss: 0.6695 - val_accuracy: 0.7900\n",
      "Epoch 22/25\n",
      "220/220 [==============================] - 48s 217ms/step - loss: 0.3240 - accuracy: 0.8824 - val_loss: 0.6652 - val_accuracy: 0.8000\n",
      "Epoch 23/25\n",
      "220/220 [==============================] - 48s 217ms/step - loss: 0.3180 - accuracy: 0.8864 - val_loss: 0.7012 - val_accuracy: 0.7857\n",
      "Epoch 24/25\n",
      "220/220 [==============================] - 48s 217ms/step - loss: 0.2977 - accuracy: 0.8894 - val_loss: 0.7454 - val_accuracy: 0.7927\n",
      "Epoch 25/25\n",
      "220/220 [==============================] - 48s 218ms/step - loss: 0.2986 - accuracy: 0.8911 - val_loss: 0.6808 - val_accuracy: 0.8077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26f9f225bb0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x=training_set,validation_data=test_set,epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.save(\"cnn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64, 64, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image = image.load_img(\"pred/51.jpg\",target_size = (64,64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image,axis = 0)\n",
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = cnn.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'buildings': 0,\n",
       " 'forest': 1,\n",
       " 'glacier': 2,\n",
       " 'mountain': 3,\n",
       " 'sea': 4,\n",
       " 'street': 5}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(result) #171"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(result) #103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(result) #51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(\"pred/51.jpg\")\n",
    "img = image.img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
